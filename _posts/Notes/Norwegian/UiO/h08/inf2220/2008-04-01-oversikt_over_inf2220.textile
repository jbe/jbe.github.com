---
layout: post
title: "Oversikt over inf2220 ved UiO høsten 08"
published: true
categories:
  - Notes
  - UiO
  - inf2220
---

h4. Hva man skal kunne

* Kapittel 7, 8, 9, 10, 11 og 12 fra læreboken
* Foilene (i "undervisningsplanen":http://www.uio.no/studier/emner/matnat/ifi/INF2220/h08/undervisningsplan.xml)

h4. Hva man kan vente seg

Det sies at det har vært regimeskifte hos eksamensmakerne, og at årets eksamen derfor ikke nødvendigvis blir som de gamle. Ukesoppgaver burde derimot være relevante. Det er under forelesning blitt hintet om at det er god _sannsynlighet for grafer på eksamen_.


h4. I dette dokumentet kommer jeg, overmodig, til å prøve å dekke

* Generell terminologi
* Trær
* Maps og hashing
* Kombinatorisk søk
* Prioritetskø og heap
* Grafer
* Sortering
* Disjunkte mengder
* Tekstalgoritmer

La oss dra ut på en magisk reise!

h2{background-color: yellow}. Generell terminologi

Kurset handler om _algoritmer_. De kan defineres på mange måter. En algoritme kan sies å ha:

* Endelighet
* Definerbarhet
* Input
* Output
* Effektivitet

Effektivitet beskrives ved _Big-Oh_-notasjon, slik som @O(n)@ eller @O(n²)@.

Big-O bryr seg vanligvis ikke med konstanter. @n/2@ eller @10n@ svarer dermed til @n@, mens @n²+n+1@ svarer til @n²@. log ~2~ n og log ~10~ n, svarer begge til log n. Også videre.

h2{background-color: yellow}. Trær 

Et tre er en mengde noder forbundet av kanter, slik at kantene ikke danner sirkler. Vi har som oftest også en _rot-node_. Denne har ikke foreldre, mens alle andre noder enten vil være barn av rotnoden, eller barn av andre barn av rotnoden. Forplantningsretningen kan med andre ord sies å gå bort fra rotnoden, mens.. hmm.. foreldringsretningen går mot den? Hvis jeg noen gang blir foreleser, skal jeg konsekvent bruke disse begrepene. Treet er med andre ord en type graf. Andre begreper:

|_Bladnode_|En node uten barn|
|_Dybde (node)_|Avstand fra roten|
|_Høyde (node)_|Avstand fra fjerneste bladnode|
|_Høyde (tre)_|Rotens høyde|

*Traversering* av treet kan for eksempel gjøres _prefix_, _infix_, eller _postfix_. Prefiks gir nodene i den rekkefølgen rekursjonen når dem. Infiks gir typisk elementene i sortert rekkefølge. Postfiks er en type lim man bruker i postvesenet.

I *binære trær* har hver node maksimalt to barn. Enkelt og greit å forholde seg til.

*Rød-sorte trær* er binære trær der vi følger noen bestemte regler, for å sikre at treet alltid er rimelig godt balansert, og at treets høyde følger O(log n) selv om innsettingsrekkefølgen ikke er optimal.

* Hver node er enten sort eller rød
* Roten er sort
* Røde noder har sorte barn
* Enhver bane fra en gitt node til dens etterfølgende bladnoder, skal inneholde samme antall sorte noder.

Om min intuisjon er rett, medfører også dette at:

* Treet ikke kan ha nullpekere over sorte noder
* Nodene etterhvert legger seg "lagvis", slik at noder på samme nivå får samme farge

Når vi beskriver innsetting i treet, brukes ofte disse benevnelsene:

|X:|Noden vi setter inn, med relasjonene..|
|P:|foreldre-node|
|G:|besteforeldre-node|
|S:|onkel/tante-node|

Hver gang kravene ikke lenger oppfylles som følge av en innsetting, tafser vi litt på treet, til det kommer i balanse. Mer presist: Rød-sorte trær åpner for en kjekk innsettingsalgoritme:

* Sett inn X i søketreet som vanlig og farg X rød.
* Hvis P er sort, er vi nå ferdige.
* Hvis P er rød:
** Hvis S er sort: roter treet.
** Hvis S er rød: farg om treet.
* Hvis x nå er roten, farg sort

Omfarging og rotasjon forstår man intuitivt etter å ha sett noen illustrasjoner og eksempler. <a href="http://en.wikipedia.org/wiki/Red-black_trees">Live by Wikipedia, die by Wikipedia</a>.

Som en digresjon:

I *kolleksjonsklasser* basert på trær, kan iteratoren implementeres ved å bruke en stakk-datastruktur for å representere informasjonen som ellers hadde samlet seg i funksjons-stakken under en vanlig rekursjon. Deretter er det bare å gli mot venstre som ellers, mens man samler høyre-nodene man passerer i stakken, og vender tilbake til disse så snart man når en bladnode.

*Balanserte trær* er fint. I *AVL-trær* skal hver node sine barn ha en høydeforskjell på maksimalt 1. Høyden til et AVL-tre med _n_ verdier er _O_(log _n_). Hver gang treet ikke lenger oppfyller kravene, må det roteres, slik at balansen gjenopprettes. AVL gjør dette rekursivt.

( _a_ , _b_ )-trær har minimalt _a_, og maksimalt _b_ barn. Det bruker en intern datastruktur (liste) for nøklene i hver node. Vi kan gi enda en invariant for ( _a_ , _b_ )-trær, ved å si at alle eksterne noder skal ha samme dybde. Denne typen trær begrenser antall disk-aksesser for å komme til en løvnode.

*B-trær* av orden _M_:

* Alle data lagres i bladnodene
* Interne noder har mindre enn M nøkler for søking
** Der nøkkel _i_ angir minste verdi i subtre _i_+1
* Interne noder skal ha mellom _M_ og _M_/2 barn
* Bladnoder skal ha
** Samme dybde
** Mellom _L_ og _L_/2 elementer, der _L_ er en konstant gitt for hele treet

Dette svarer omtrent til et ( _M_, 2/_M_ )-tre

h2{background-color: yellow}. Maps og hashing

Hasjkart er en ADT som brukes for fort å kunne slå opp, og hente ut, objekter fra en samling, basert på en unik nøkkel. I Java kunne vi kalle det et @Map<Key,Value>@. Verdiene lagres i en array. Indeksene må derfor genereres fra nøkkelen. For å gjøre det, trengs en hasjfunksjon som, optimalt sett

* er rask
* gir jevn fordeling

Kartet må også kunne håndtere kollisjoner; der flere nøkler hasjer til samme indeks. Vi bør også velge en passende størrelse på arrayet. Den bør ikke være for stor; men vi må ha nok luft til å unngå kollisjoner.

Fantastisk nok, kan innsetting, sletting og søk gjøres i _konstant tid_. Det kan være hensiktsmessig å la tabellstørrelsen være et primtall, sies det.

To former for kollisjonshåndtering:

|_Åpen hashing/separate chaining_|Samler elementer med samme hash i en liste|
|_Lukket hashing_|Prøver ny indeks til vi finner en ledig|

Lukket hashing krever dermed større tabell. Noen muligheter for prøving:

* Lineær
* Kvadratisk
* Dobbel hashing; bruker ny funksjon

Når tabellen blir full, må vi gjøre et *Rehash*:

# Lag en ny tabell, omkring dobbelt så stor som den forrige
# Flytt over alle elementene

h2{background-color: yellow}. Kombinatorisk søk

er som oftest et rekursivt søk etter bestemte egenskaper, eller _permutasjoner_.

|Har:|Et endelig antall elementer|
|Skal:|Finne en rekkefølge, gjøre et utplukk, lage en oppdeling|
|Eksempel:|Hvordan plasserer man 8 dronninger på et sjekkbrett, slik at ingen kan slå hverandre.|

Et eksempel på generering av *permutasjoner* er å finne alle mulige sekvenser av tallene 0, 1 og 2 med lengde n. Dette kan beskrives som et tre, og løses rekursivt.

Avskjær så tidlig som mulig.

*Basistilfellet* er det tilfellet rekursjonen stopper ved.

..etter disse få notatene, forlot jeg desverre forelesningen, til fordel for andre distraksjoner.

h2{background-color: yellow}. Prioritetskø og Heap

Brukes når man ønsker mer kontroll enn f.eks over en FIFO eller LIFO/Stack. Et eksempel er job-scheduling.

* Hvert element har en prioritet, gitt ved et heltall
* Denne kan betraktes som tiden vi maksimalt kan vente

Det vi ønsker, er å kunne sette inn elementer, og å ta ut det fremste elementet. Det kan implementeres via en liste, et søketre eller en heap, hvorav sistnevnte er det vanligste.

*En binær heap* er et binærtre med et strukturkrav og et ordningskrav:
* Alle nivåer skal være fulle før vi begynner på neste. Dette kalles også et komplett binærtre.
* Barn er alltid større eller lik sine foreldre.

At treet er komplett, betyr at
* det er i "perfekt balanse"
* maks høydeforskjell mellom bladnoder er 1
* maksimal høyde er log<sub>2</sub>(n)

Et komplett binærtre er i optimal balanse. Fordi treet i heapen er komplett, kan vi lagre det i en array, og for en node med indeks @i@ vite at
* i &times; 2 = venstre barn
* i &times; 2 + 1 = høyre barn
* i / 2 = forelder

Rotens indeks er @0@.

*Innsetting* gjøres til første ledige plass. For å få rekkefølgen til å stemme, må vi boble opp eller ned helt til alt stemmer. Kalles gjerne _up-heap bubbling_ eller _percolate up_.

*Popping* (ikke "dette":http://www.youtube.com/watch?v=-IUv1oyq6eI) gjøres ved å fjerne rota, og la det siste elementet bli ny rot, for deretter å boble den nedover til riktig posisjon, så lenge den er større enn et av barna. Hvis den er større enn begge, velger vi den minste.

@pop@ og @add@ er @O(log(n))@

|bygges (insert)|O(n x log(n))|
|tar ut (delMin)|O(n x log(n))|
|worst case|2 O(n x log(n))|

h2{background-color: yellow}. Grafer

En graf har en mengde noder, og en mengde kanter. @(V,E)@ er henholdsvis antall noder og antall kanter i grafen. Hver kant er et par av noder. Grafer kan være..

|_vektet_|hver kant er tilordnet en verdi|
|_rettet_|hver kant har retning; dvs forbinder bare en vei|
|_sterkt forbundet_|det er mulig å gå fra en hvilken som helst node til en hvilken som helst node|
|_svakt forbundet_|alle noder henger sammen|
|_asyklisk_|det er ikke mulig å traversere grafen i ring|

*Representasjon av grafer* kan f.eks gjøres ved hjelp av

* en binær nabo-matrise, evt. vekter
* en nabo-liste i hver node

Nodebedgreper:

|Inngrad|antall innkommende kanter|
|Utgrad|antall utgående kanter|

Under rekursiv *traversering*, må vi ofte markere hvilke noder som allerede er besøkt, for å unngå evige løkker.

*Korteste vei* mellom to noder i en graf uten negative kanter, kan vi finne via et rekursivt søk etter målnoden, fra startnoden

En *topologisk sortering* kan gjøres av en rettet, asyklisk graf. Den gir bare gyldige traverseringsrekkefølger, men er ikke begrensen til _en_ bestemt bane gjennom grafen. En algoritme er:

# Finn en node med inngrad 0.
# Legg den inn i resultatet, fjern den, og fjern utkantene.
# Gå tilbake til 1, med mindre vi er ferdig med alle noder.

Dette kan gjøres i @O(|V|²)@-tid.

*Minimale spenntrær* er et kult ord. Grafen G sitt minimale spenntre, er et tre slik at nodene er forbundet, til lavest mulig kostnad. De finnes bare for sammenhengende grafer. *Dijkstras algoritme* funker fett:

Mens den kjører, tar vi for hver node vare på avstand, forrige node, om noden er besøkt og neste node. Vi har også en aktiv node. Initialverdiene er:

|&clubs;|startnode|andre noder|
|avstand|0|&#8734;|
|forrige node|\2. null|
|besøkt|\2. false|

Dansen går som dette..

# Startnode merkes aktiv
# Aktiv node merkes besøkt
# Aktiv nodes nabonoders avstand oppdateres til aktiv node pluss relevant kant
# Aktiv node settes til den av _alle_ nodene med lavest avstand
# Returner til 2 så lenge det finnes ubesøkte noder

For å forstå hvordan dette virker, kan man tenke seg et nett av tråder, der knutene svarer til noder, og trådene mellom dem og deres lengde svarer til kantene og deres vekt. Om vi så slipper dette nettet på bakken, og plukker opp en av knutene, vil nodene løfte seg fra bakken i en rekkefølge som svarer til deres avstand fra knuten vi plukket opp, via de andre knutene. Det er hva denne algoritmen også gjør.

h2{background-color: yellow}. Sortering

*Bubble sort*

|Average|n log n|
|Worst|n²|

<pre name="code" class="ruby:nocontrols">
def bubbleSort( list )
  swapped = false
  do
    for each i in 0 to list.length - 1 do
      if list[ i ] > list[ i + 1 ]
        swap( A[ i ], A[ i + 1 ] )
        swapped = true
      end
    end
  while swapped
end
</pre>


*Insert sort*

|Average|n²|
|Worst|n²|

<pre name="code" class="ruby:nocontrols">
insertionSort(array A)
begin
    for i := 1 to length[A] do
    begin
        value := A[i];
        j := i-1;
        while j ≥ 0 and A[j] > value do
        begin
            A[j + 1] := A[j];
            j := j-1;
        end;
        A[j+1] := value;
    end;
end;
</pre>


*Shell sort*

|Average|O(n²)|
|Worst|O(n²)|

<pre name="code" class="java:nocontrols">
public static void shellSort(int[] a) {
    for (int increment = a.length / 2; increment > 0;
          increment = (increment == 2 ? 1 : (int) Math.round(increment / 2.2))) {
        for (int i = increment; i < a.length; i++) {
            int temp = a[i];
            int j;
            for (j = i; j >= increment && a[j - increment] > temp; j -= increment){
                a[j] = a[j - increment];
            }
            a[j] = temp;
        }
    }
}
</pre>


*Tree sort*

Sorterer ved å sette inn i et binært søketre, og deretter traversere treet.

|Average|O(n log n)|
|Worst|O(n²)|

*Quick sort*

|Average|O(n log n)|
|Worst|O(n²)|

<pre name="code" class="ruby:nocontrols">
  function partition(array, left, right, pivotIndex)
     pivotValue := array[pivotIndex]
     swap array[pivotIndex] and array[right] // Move pivot to end
     storeIndex := left
     for i  from  left to right − 1
         if array[i] ≤ pivotValue 
             swap array[i] and array[storeIndex]
             storeIndex := storeIndex + 1
     swap array[storeIndex] and array[right] // Move pivot to its final place
     return storeIndex
</pre>

*Merge sort*

|Average|O(n log n)|
|Worst|O(n log n)|

*Radix sort (n-pass)*

|Whatever|optimal! O(n)|

h2{background-color: yellow}. Disjunkte mengder

*Ekvivalensrelasjoner* er binære relasjoner, som også er...

|_symmetriske_|@a ~ b@ &rarr; @b ~ a@|
|_refleksive_|@a ~ a@|
|_transitive_|@a ~ b ^ b ~ c@ &rarr; @a ~ c@|

Elementene i en mengde kan deles inn i ekvivalensklasser, etter sin likhet. Disse mengdene er disjunkte, per definisjonen ovenfor.

*Dynamisk ekvivalens* er et problemområde. Vi kan tenke oss interfacet @find(a)@ &rarr; @EnEkvivalensKlasse@ og @union(a,b)@ som forener @a@ og @b@.

ADT-en kan implementeres som en ekvivalens-matrise; men dette blir veldig plasskrevende for store mengder.

En bedre ADT kan bygges på _to måter_:


|&clubs;|find|union|hvordan det funker|
|_Rask find_|@O(1)@|@O(log n)@|Lagrer ekvivalensklasse per element. Lurt å endre minste mengde til største; ikke omvendt.|
|_Rask union_|@O(log n)@|@O(1)@|Har en skog, der hver rot identifiserer en ekvivalensklasse. Minste tre bør legges til som subtre i det største.|

h2{background-color: yellow}. Tekstalgoritmer

*Boyer Moore*, er det noe som heter. La oss håpe det ikke dukker opp på eksamen.
